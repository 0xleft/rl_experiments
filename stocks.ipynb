{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af129ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torchmetrics\n",
    "from typing import Optional, List, Dict\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer, MultiheadAttention\n",
    "\n",
    "class PricePredictionLightning(pl.LightningModule):\n",
    "    def __init__(self, hparams=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        \n",
    "        # Initialize model layers\n",
    "        self.norm = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.LayerNorm([5000])\n",
    "        )\n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=5000,\n",
    "            nhead=8,\n",
    "            dim_feedforward=128,\n",
    "            dropout=0.1,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(5000, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_mse = torchmetrics.MeanSquaredError()\n",
    "        self.val_mse = torchmetrics.MeanSquaredError()\n",
    "        self.test_mse = torchmetrics.MeanSquaredError()\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if hasattr(m, 'bias') and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(2, 0, 1)  # [5000, batch_size, 3]\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=0)\n",
    "        x = self.mlp(x)\n",
    "        return F.softplus(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        mse = self.train_mse(y_hat, y)\n",
    "        \n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_mse', mse, prog_bar=True)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        mse = self.val_mse(y_hat, y)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_mse', mse, prog_bar=True)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        mse = self.test_mse(y_hat, y)\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_mse', mse)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        self.log('train_epoch_loss', avg_loss)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        self.log('val_epoch_loss', avg_loss)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=1e-4,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        \n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "def train_model(model, train_dataloader, val_dataloader, test_dataloader=None,\n",
    "                max_epochs=100, gpus=0, checkpoint_dir='./checkpoints'):\n",
    "    # Initialize callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_top_k=3,\n",
    "        verbose=True,\n",
    "        dirpath=checkpoint_dir\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    logger = TensorBoardLogger('logs', name='price_prediction')\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        gpus=gpus,\n",
    "        callbacks=[checkpoint_callback, early_stopping],\n",
    "        logger=logger,\n",
    "        gradient_clip_val=1.0,\n",
    "        accumulate_grad_batches=2,\n",
    "        precision=16,  # Mixed precision training\n",
    "        progress_bar_refresh_rate=30\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model, train_dataloader, val_dataloaders=val_dataloader)\n",
    "    \n",
    "    # Optional test evaluation\n",
    "    if test_dataloader:\n",
    "        trainer.test(model, test_dataloaders=test_dataloader)\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f2442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "tickers = \"AAPL NVDA MSFT GOOG AMZN GOOGL META AVGO TSLA TSM LLY WMT V JPM MA XOM UNH ORCL COST PG JNJ NFLX ABBV HD NVO BABA SAP BAC KO TMUS ASML CVX CRM TM MRK CSCO PM AZN ABT IBM WFC NVS MCD LIN GE SHEL PEP ACN HSBC TMO T PLTR\"\n",
    "\n",
    "# download from last month\n",
    "yf.download(tickers, start=\"2025-03-10\", interval='1m', period=\"1d\", repair=True, auto_adjust=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e96ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tickers = \"AAPL NVDA MSFT GOOG\"#  AMZN GOOGL META AVGO TSLA TSM LLY WMT V JPM MA XOM UNH ORCL COST PG JNJ NFLX ABBV HD NVO BABA SAP BAC KO TMUS ASML CVX CRM TM MRK CSCO PM AZN ABT IBM WFC NVS MCD LIN GE SHEL PEP ACN HSBC TMO T PLTR\"\n",
    "dat = yf.Tickers(tickers)\n",
    "\n",
    "from yfinance import cache\n",
    "history = yf.download(tickers, start=\"2024-01-01\", end=\"2025-01-01\", interval=\"1d\")\n",
    "# history = dat.history(period=\"1mo\", interval=\"1m\", group_by='ticker')\n",
    "history.index = history.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "history.to_excel(\"history.xlsx\")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca842531",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data = {}\n",
    "\n",
    "for ticker in tickers.split():\n",
    "    ticker_data = history[ticker]\n",
    "    \n",
    "    if len(ticker_data) >= 1000:\n",
    "        ticker_data = ticker_data.iloc[:1000]\n",
    "        \n",
    "        reshaped_data[ticker] = np.array([\n",
    "            ticker_data['Open'].values,\n",
    "            ticker_data['High'].values,\n",
    "            ticker_data['Low'].values,\n",
    "            ticker_data['Volume'].values\n",
    "        ])\n",
    "    else:\n",
    "        print(f\"Not enough data points for {ticker}\")\n",
    "\n",
    "def create_dataset(data):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(create_dataset(reshaped_data))\n",
    "val_dataset = TensorDataset(create_dataset(reshaped_data))\n",
    "test_dataset = TensorDataset(create_dataset(reshaped_data))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = PricePredictionLightning()\n",
    "trainer = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    test_dataloader=test_loader,\n",
    "    max_epochs=100,\n",
    "    gpus=1 if torch.cuda.is_available() else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241dbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yahooquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009dbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahooquery import Ticker\n",
    "import pickle\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "tickers = \"AVGO TSLA TSM LLY WMT V JPM MA XOM UNH ORCL COST PG JNJ NFLX ABBV HD NVO BABA SAP BAC KO TMUS ASML CVX CRM TM MRK CSCO PM AZN ABT IBM WFC NVS MCD LIN GE SHEL PEP ACN HSBC TMO T PLTR\".split(\" \")\n",
    "\n",
    "for ticker_label in tickers:\n",
    "    ticker = Ticker(ticker_label, asynchronous=True)\n",
    "    os.makedirs(f'stock_data/{ticker_label}', exist_ok=True)\n",
    "    for year in range(2011, 2025):\n",
    "        for month in range(1, 13):\n",
    "            startdate = datetime.date(year, month, 1)\n",
    "            df = ticker.history(start=startdate.strftime(\"%Y-%m-%d\"), period='1mo', interval='1m')\n",
    "            with open(f'stock_data/{ticker_label}/{year}_{month}.pkl', 'wb') as f:\n",
    "                pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b3c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
